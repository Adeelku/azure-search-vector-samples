{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load .env file (Copy .env-sample to .env and update accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv() # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "search_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_embedding_deployment_id = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_ID\"]\n",
    "\n",
    "# Two indexes for different text splitting strategies\n",
    "recursivetextsplitter_searchindex = os.environ[\"AZURE_SEARCH_LANGCHAIN_RECURSIVETEXTSPLITTER_INDEX\"]\n",
    "spacytextsplitter_searchindex = os.environ[\"AZURE_SEARCH_LANGCHAIN_SPACYTEXTSPLITTER_INDEX\"]\n",
    "\n",
    "search_credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup sample resources for embedding chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "azure_openai_client = None\n",
    "if azure_openai_key:\n",
    "    azure_openai_client = AzureOpenAI(\n",
    "        api_key=azure_openai_key, \n",
    "        api_version=\"2023-05-15\",\n",
    "        azure_deployment=azure_openai_embedding_deployment_id,\n",
    "        azure_endpoint=azure_openai_endpoint)\n",
    "else:\n",
    "    azure_openai_client = AzureOpenAI(\n",
    "        azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "        api_version=\"2023-05-15\",\n",
    "        azure_deployment=azure_openai_embedding_deployment_id,\n",
    "        azure_endpoint=azure_openai_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup sample resources for recursive text splitter chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created recursive text splitter index\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from lib.common import (\n",
    "    create_search_index,\n",
    ")\n",
    "\n",
    "search_index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "rts_searchindex = create_search_index(\n",
    "    recursivetextsplitter_searchindex,\n",
    "    azure_openai_endpoint,\n",
    "    azure_openai_embedding_deployment_id,\n",
    "    azure_openai_key\n",
    ")\n",
    "search_index_client.create_or_update_index(rts_searchindex)\n",
    "\n",
    "print(\"Created recursive text splitter index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "loader = PyPDFLoader(os.path.join(\"data\", \"earth_at_night_508.pdf\"))\n",
    "pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk PDF using Recursive text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "   chunk_size=2000, \n",
    "   chunk_overlap=500,\n",
    "   length_function=len,\n",
    "   is_separator_regex=False\n",
    ")\n",
    "\n",
    "recursive_text_splitter_chunks = recursive_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Recursive text splitter chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_text_splitter_embeddings = azure_openai_client.embeddings.create(input=[chunk.page_content for chunk in recursive_text_splitter_chunks], model=azure_openai_embedding_deployment_id)\n",
    "recursive_text_splitter_embeddings = [result.embedding for result in recursive_text_splitter_embeddings.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload chunks to search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded chunks and embeddings for recursive text splitter\n"
     ]
    }
   ],
   "source": [
    "recursive_search_client = search_index_client.get_search_client(recursivetextsplitter_searchindex)\n",
    "\n",
    "docs = [\n",
    "    {\n",
    "        \"parent_id\": \"0\",\n",
    "        \"chunk_id\": f\"{i}_earth_at_night_508_pdf\",\n",
    "        \"chunk\": chunk.page_content,\n",
    "        \"title\": \"earth_at_night_508.pdf\",\n",
    "        \"vector\": recursive_text_splitter_embeddings[i]\n",
    "    }\n",
    "    for i, chunk in enumerate(recursive_text_splitter_chunks)\n",
    "]\n",
    "\n",
    "recursive_search_client.upload_documents(docs)\n",
    "\n",
    "print(\"Uploaded chunks and embeddings for recursive text splitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Chunk PDF using Spacey text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "\n",
    "spacey_text_splitter = SpacyTextSplitter(\n",
    "   pipeline=\"sentencizer\", # See https://spacy.io/models/en/ for available models\n",
    "   chunk_size=2000,\n",
    "   chunk_overlap=500\n",
    ")\n",
    "\n",
    "spacey_text_splitter_chunks = spacey_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Embed Spacy text splitter chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_text_splitter_embeddings = azure_openai_client.embeddings.create(input=[chunk.page_content for chunk in spacey_text_splitter_chunks], model=azure_openai_embedding_deployment_id)\n",
    "spacy_text_splitter_embeddings = [result.embedding for result in spacy_text_splitter_embeddings.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Upload chunks to search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spacy text splitter index\n",
      "Uploaded chunks and embeddings for spacy text splitter\n"
     ]
    }
   ],
   "source": [
    "search_index_client = SearchIndexClient(endpoint=search_endpoint, credential=search_credential)\n",
    "sts_searchindex = create_search_index(\n",
    "    spacytextsplitter_searchindex,\n",
    "    azure_openai_endpoint,\n",
    "    azure_openai_embedding_deployment_id,\n",
    "    azure_openai_key\n",
    ")\n",
    "search_index_client.create_or_update_index(sts_searchindex)\n",
    "\n",
    "print(\"Created spacy text splitter index\")\n",
    "\n",
    "spacy_search_client = search_index_client.get_search_client(spacytextsplitter_searchindex)\n",
    "\n",
    "docs = [\n",
    "    {\n",
    "        \"parent_id\": \"0\",\n",
    "        \"chunk_id\": f\"{i}_earth_at_night_508_pdf\",\n",
    "        \"chunk\": chunk.page_content,\n",
    "        \"title\": \"earth_at_night_508.pdf\",\n",
    "        \"vector\": spacy_text_splitter_embeddings[i]\n",
    "    }\n",
    "    for i, chunk in enumerate(spacey_text_splitter_chunks)\n",
    "]\n",
    "\n",
    "spacy_search_client.upload_documents(docs)\n",
    "\n",
    "print(\"Uploaded chunks and embeddings for spacy text splitter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
